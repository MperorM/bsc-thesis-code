{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37664bitfa9331d9b9e448c497d241bf524ea135",
   "display_name": "Python 3.7.6 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset downloaded from here: https://github.com/wuhuikai/MSC\n",
    "\n",
    "To reproduce notebooks, change absolute paths accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "zvz = \"/Users/mathiaskirkbonde/Documents/parsed_replays/GlobalFeatureVector/Zerg_vs_Zerg/Zerg/\"\n",
    "pvp = \"/Users/mathiaskirkbonde/Documents/parsed_replays/GlobalFeatureVector/Protoss_vs_Protoss/Protoss/\"\n",
    "tvt = \"/Users/mathiaskirkbonde/Documents/parsed_replays/GlobalFeatureVector/Terran_vs_Terran/Terran/\"\n",
    "\n",
    "matchups = [zvz, pvp, tvt]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to reproduce for races zerg and protoss, rewrite the following code block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "allFileNames = os.listdir(tvt)\n",
    "#TODO: This is bad and ugly, rewrite this\n",
    "for i in range(0, int(len(allFileNames) * 0.10)):\n",
    "    if \".npz\" in allFileNames[i]:\n",
    "        shutil.move(tvt + allFileNames[i], tvt + \"/test\")\n",
    "\n",
    "for i in range(int(len(allFileNames) * 0.10), int(len(allFileNames) * 0.2)):\n",
    "    if \".npz\" in allFileNames[i]:\n",
    "        shutil.move(tvt + allFileNames[i], tvt + \"/validation\")\n",
    "\n",
    "for i in range(int(len(allFileNames) * 0.2), int(len(allFileNames))):\n",
    "    if \".npz\" in allFileNames[i]:\n",
    "        shutil.move(tvt + allFileNames[i], tvt + \"/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NotADirectoryError",
     "evalue": "[Errno 20] Not a directory: '/Users/mathiaskirkbonde/Documents/parsed_replays/GlobalFeatureVector/Zerg_vs_Zerg/Zerg/train/'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-7337090ff130>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# get lengths of each split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmatchup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmatchups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mallFileNames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatchup\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"train/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"training set size: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mallFileNames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mallFileNames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatchup\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"test/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotADirectoryError\u001b[0m: [Errno 20] Not a directory: '/Users/mathiaskirkbonde/Documents/parsed_replays/GlobalFeatureVector/Zerg_vs_Zerg/Zerg/train/'"
     ]
    }
   ],
   "source": [
    "# get lengths of each split\n",
    "\n",
    "allFileNames = os.listdir(tvt + \"train/\")\n",
    "print(\"training set size: \" + len(allFileNames))\n",
    "allFileNames = os.listdir(tvt + \"test/\")\n",
    "print(\"test set size: \" + len(allFileNames))\n",
    "allFileNames = os.listdir(tvt + \"validation/\")\n",
    "print(\"validation set size: \" + len(allFileNames))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create H5 training file, used for training LSTM on Google Colab. This is done as loading individual replays from Drive is exceedingly slow, H5 format allows loading replays in batches without keeping the entire file in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sets = [\"train\", \"test\", \"validation\"]\n",
    "\n",
    "for name in sets:\n",
    "    d = (\n",
    "        \"/Users/mathiaskirkbonde/Documents/parsed_replays/GlobalFeatureVector/Terran_vs_Terran/Terran/\"\n",
    "        + name\n",
    "    )\n",
    "    replays = []\n",
    "\n",
    "    for r, d, f in os.walk(d):\n",
    "        for file in f:\n",
    "            if \".npz\" in file:\n",
    "                path = os.path.join(r, file)\n",
    "                # files.append(os.path.join(r, file)\n",
    "                replays.append(sparse.load_npz(path))\n",
    "\n",
    "    replays = np.asarray(replays)\n",
    "\n",
    "    # create h5 object\n",
    "    hf = h5sparse.File(f\"./datasets/{name}.h5\", \"w\")\n",
    "\n",
    "    # store each replay as sparse matrix\n",
    "    for i, replay in enumerate(replays):\n",
    "        hf.create_dataset(f\"sparse/{i}\", data=replay)\n",
    "\n",
    "    hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}